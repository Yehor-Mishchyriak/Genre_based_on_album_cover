{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ccba498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8058d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/yehormishchyriak/Desktop/qac239_final_project/clean_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f14205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7065eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 for pretrained CNNs\n",
    "    transforms.ToTensor(),         # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for pretrained models\n",
    "])\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_image(image_index):\n",
    "    image = Image.open(f\"/Users/yehormishchyriak/Desktop/qac239_final_project/album_covers/{image_index}.jpg\").convert('RGB')  # Ensure image is RGB\n",
    "    return transform(image)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['image_tensor'] = df['album_id'].apply(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00f139c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_tensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(0.9646), tensor(0.9474), tensor(0.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(-1.2274), tensor(-1.1589), tensor(-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(2.2489), tensor(2.2489), tensor(2.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(-1.3644), tensor(-1.4500), tensor(-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[tensor(0.5022), tensor(0.5193), tensor(0.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2155</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(-2.1008), tensor(-2.1008), tensor(-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>2157</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[tensor(-0.1143), tensor(-0.1143), tensor(-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>2159</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[tensor(-0.2856), tensor(-0.2856), tensor(-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>2160</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[tensor(2.1290), tensor(2.1633), tensor(0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>2162</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[tensor(-1.9638), tensor(-1.9638), tensor(-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      album_id  genre                                       image_tensor\n",
       "0            0      0  [[[tensor(0.9646), tensor(0.9474), tensor(0.96...\n",
       "1            1      0  [[[tensor(-1.2274), tensor(-1.1589), tensor(-1...\n",
       "2            2      1  [[[tensor(2.2489), tensor(2.2489), tensor(2.24...\n",
       "3            4      0  [[[tensor(-1.3644), tensor(-1.4500), tensor(-1...\n",
       "4            6      4  [[[tensor(0.5022), tensor(0.5193), tensor(0.50...\n",
       "...        ...    ...                                                ...\n",
       "1603      2155      1  [[[tensor(-2.1008), tensor(-2.1008), tensor(-2...\n",
       "1604      2157      2  [[[tensor(-0.1143), tensor(-0.1143), tensor(-0...\n",
       "1605      2159      3  [[[tensor(-0.2856), tensor(-0.2856), tensor(-0...\n",
       "1606      2160      4  [[[tensor(2.1290), tensor(2.1633), tensor(0.89...\n",
       "1607      2162      4  [[[tensor(-1.9638), tensor(-1.9638), tensor(-1...\n",
       "\n",
       "[1608 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "070511a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"album_covers_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cbed3",
   "metadata": {},
   "source": [
    "### Intended split: Training - 80%, Validation - 10%, Testing - 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9cd627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 1286\n",
      "Validation Set Size: 161\n",
      "Testing Set Size: 161\n"
     ]
    }
   ],
   "source": [
    "# split into 80% training and 20% temp (validation + testing)\n",
    "train_data, temp_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# split temp data into 50% validation and 50% testing\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training Set Size:\", len(train_data))\n",
    "print(\"Validation Set Size:\", len(validation_data))\n",
    "print(\"Testing Set Size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7891fb",
   "metadata": {},
   "source": [
    "## DATASET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40712297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image and label\n",
    "        image_path = (f\"/Users/yehormishchyriak/Desktop/qac239_final_project/album_covers/{self.dataframe.iloc[idx]['album_id']}.jpg\")\n",
    "        label = self.dataframe.iloc[idx]['genre']\n",
    "        \n",
    "        # Load and transform image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
